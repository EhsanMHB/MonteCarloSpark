# Spark implementation of the Monte Carlo integration
We know that the main use case of **Spark** is the large dataset analysis. However, it can be used also to perform compute intensive tasks as we employ it here for numerical integration problem by Monte Carlo method. The task has been explained [here](Monte%20Carlo%20Integration%20using%20Spark.pdf) in detail. 
